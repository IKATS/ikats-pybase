from multiprocessing import cpu_count

# Daemonize Gunicorn (detach)
daemon = True

# Set the number of workers based on core count
workers = cpu_count() * 2 + 1

# Threads count per worker
threads = cpu_count() * 2

# Name used in "top" or "ps" commands
name = "ikats"

# Timeout before a worker restarts if no heartbeat received (60*60*24*7 = 604800 = 7 days)
timeout = 60*60*24*7

# Preload code before instantiating workers (load faster)
preload = True

# Account to use when writing files
user = 'ikats'
group = 'ikats'

# Logs
loglevel = 'debug'
errorlog = '/logs/gunicorn_error.log'
accesslog = '/logs/gunicorn_access.log'



def post_fork(server, worker):
    server.log.info("Worker spawned (pid: %s)", worker.pid)

# Review#152461 Useless function?
def pre_fork(server, worker):
    pass

def pre_exec(server):
    server.log.info("Forked child, re-executing.")

def when_ready(server):
    server.log.info("Server is ready. Spawning workers")

def worker_int(worker):
    worker.log.info("Worker received INT or QUIT signal")

    ## get traceback info
    import threading, sys, traceback
    id2name = dict([(th.ident, th.name) for th in threading.enumerate()])
    code = []
    for threadId, stack in sys._current_frames().items():
        code.append("\n# Thread: %s(%d)" % (id2name.get(threadId,""),
            threadId))
        for filename, lineno, name, line in traceback.extract_stack(stack):
            code.append('File: "%s", line %d, in %s' % (filename,
                lineno, name))
            if line:
                code.append("  %s" % (line.strip()))
    worker.log.debug("\n".join(code))

def worker_abort(worker):
    worker.log.info("worker received SIGABRT signal")